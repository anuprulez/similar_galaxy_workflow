{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import warnings\n",
    "import operator\n",
    "\n",
    "import h5py\n",
    "from keras.models import model_from_json\n",
    "from keras import backend as K\n",
    "from keras.utils import get_custom_objects\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "size_title = 18\n",
    "size_label = 14\n",
    "n_pred = 2\n",
    "\n",
    "\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as data_file:\n",
    "        data = json.loads(data_file.read())\n",
    "    return data\n",
    "\n",
    "def create_model(model_path):\n",
    "    \n",
    "    reverse_dictionary = dict((str(v), k) for k, v in dictionary.items())\n",
    "    model_weights = list()\n",
    "    weight_ctr = 0\n",
    "    while True:\n",
    "        try:\n",
    "            d_key = \"weight_\" + str(weight_ctr)\n",
    "            weights = trained_model.get(d_key).value\n",
    "            model_weights.append(weights)\n",
    "            weight_ctr += 1\n",
    "        except Exception as exception:\n",
    "            break\n",
    "    # set the model weights\n",
    "    loaded_model.set_weights(model_weights)\n",
    "    return loaded_model, dictionary, reverse_dictionary, compatibile_tools\n",
    "\n",
    "\n",
    "def verify_model(model, tool_sequence, labels, dictionary, reverse_dictionary, compatible_tools, class_weights, topk=20, max_seq_len=25):\n",
    "    tl_seq = tool_sequence.split(\",\")\n",
    "    last_tool_name = reverse_dictionary[str(tl_seq[-1])]\n",
    "    last_compatible_tools = compatible_tools[last_tool_name]\n",
    "    sample = np.zeros(max_seq_len)\n",
    "    for idx, tool_id in enumerate(tl_seq):\n",
    "        sample[idx] = int(tool_id)\n",
    "    sample_reshaped = np.reshape(sample, (1, max_seq_len))\n",
    "\n",
    "    tool_sequence_names = [reverse_dictionary[str(tool_pos)] for tool_pos in tool_sequence.split(\",\")]\n",
    "    \n",
    "    # predict next tools for a test path\n",
    "    prediction = model.predict(sample_reshaped, verbose=0)\n",
    "    \n",
    "    weight_val = list(class_weights.values())\n",
    "    weight_val = np.reshape(weight_val, (len(weight_val),))\n",
    "    \n",
    "    prediction = np.reshape(prediction, (prediction.shape[1],))\n",
    "    \n",
    "    prediction = prediction / float(np.max(prediction))\n",
    "    \n",
    "    prediction_pos = np.argsort(prediction, axis=-1)\n",
    "\n",
    "    # get topk prediction\n",
    "    topk_prediction_pos = prediction_pos[-topk:]\n",
    "    topk_prediction_val = [int(prediction[pos] * 100) for pos in topk_prediction_pos]\n",
    "    \n",
    "    # read tool names using reverse dictionary\n",
    "    pred_tool_ids = [reverse_dictionary[str(tool_pos)] for tool_pos in topk_prediction_pos if tool_pos > 0]\n",
    "    actual_next_tool_ids = list(set(pred_tool_ids).intersection(set(last_compatible_tools.split(\",\"))))\n",
    "\n",
    "    pred_tool_ids_sorted = dict()\n",
    "    for (tool_pos, tool_pred_val) in zip(topk_prediction_pos, topk_prediction_val):\n",
    "        try:\n",
    "            tool_name = reverse_dictionary[str(tool_pos)]\n",
    "            if tool_name not in last_tool_name and tool_name in actual_next_tool_ids: #tool_name in actual_next_tool_ids and \n",
    "                pred_tool_ids_sorted[tool_name] = tool_pred_val\n",
    "        except:\n",
    "            continue\n",
    "    pred_tool_ids_sorted = dict(sorted(pred_tool_ids_sorted.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    \n",
    "    cls_wt = dict()\n",
    "    usg_wt = dict()\n",
    "    inv_wt = dict()\n",
    "    ids_tools = dict()\n",
    "    keys = list(pred_tool_ids_sorted.keys())\n",
    "    for k in keys:\n",
    "        try:\n",
    "            cls_wt[k] = np.round(class_weights[str(data_dict[k])], 2)\n",
    "            usg_wt[k] = np.round(usage_weights[k], 2)\n",
    "            inv_wt[k] = np.round(inverted_weights[str(data_dict[k])], 2)\n",
    "        except:\n",
    "            continue\n",
    "    print(\"Predicted tools: \\n\")\n",
    "    print(pred_tool_ids_sorted)\n",
    "    print()\n",
    "    print(\"Class weights: \\n\")\n",
    "    cls_wt = dict(sorted(cls_wt.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    print(cls_wt)\n",
    "    print()\n",
    "    print(\"Usage weights: \\n\")\n",
    "    usg_wt = dict(sorted(usg_wt.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    print(usg_wt)\n",
    "    print()\n",
    "    total_usage_wt = np.mean(list(usg_wt.values()))\n",
    "    print(\"Mean usage wt: %0.4f\" % (total_usage_wt))\n",
    "    print()\n",
    "    print(\"Inverted weights: \\n\")\n",
    "    inv_wt = dict(sorted(inv_wt.items(), key=lambda kv: kv[1], reverse=True))\n",
    "    print(inv_wt)\n",
    "    for key in pred_tool_ids_sorted:\n",
    "        ids_tools[key] = dictionary[key]\n",
    "    print()\n",
    "    print(\"Tool ids\")\n",
    "    print(ids_tools)\n",
    "    print(\"======================================\")\n",
    "    return cls_wt, usg_wt, inv_wt, pred_tool_ids_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': 'fastq_to_fasta_python', '2': 'tophat2', '3': 'eukaryotic_ncbi_submission', '4': 'gemini_windower', '5': 'antismash', '6': 'ctb_remSmall', '7': 'glimmer_build-icm', '8': 'bam_to_sam', '9': 'cshl_sort_header', '10': 'cufflinks', '11': 'gatk2_print_reads', '12': 'sam_to_bam', '13': 'blockclust', '14': 'Grouping1', '15': 'r_correlation_matrix', '16': 'ncbi_blastn_wrapper', '17': 'CONVERTER_interval_to_bedstrict_0', '18': 'ctb_compound_convert', '19': 'sort1', '20': 'vcftools_isec', '21': 'ctb_online_data_fetch', '22': 'cor2', '23': 'fasta_filter_by_length', '24': 'cshl_grep_tool', '25': 'deeptools_bamFingerprint', '26': 'cuffdiff', '27': 'fastq_quality_trimmer', '28': 'sam_bw_filter', '29': 'gatk2_realigner_target_creator', '30': 'CONVERTER_bed_to_gff_0', '31': 'random_lines1', '32': 'bams2ratio', '33': 'meme_meme', '34': 'in_tool', '35': 'rgPicardMarkDups', '36': 'deseq2', '37': 'bismark_bowtie2', '38': 'gemini_interactions', '39': 'DatamashTranspose', '40': 'gops_join_1', '41': 'ssake', '42': 'heatmapper_deepTools', '43': 'ncbi_blastp_wrapper', '44': 'FileFilter', '45': 'blastxml_to_top_descr', '46': 'gops_coverage_1', '47': 'mergeCols1', '48': 'sed_stream_editor', '49': 'vcftools_merge', '50': 'EMBOSS: transeq101', '51': 'samtools_flagstat', '52': 'bedtools_bamtofastq', '53': 'CONVERTER_Bam_Bai_0', '54': 'comp1', '55': 'cuffmerge', '56': 'fragmenter', '57': 'ctb_chemfp_mol2fps', '58': 'proteomics_search_tandem_1', '59': 'XTandemAdapter', '60': 'peakcalling_macs14', '61': 'prokaryotic_ncbi_submission', '62': 'proteomics_search_protein_prophet_1', '63': 'augustus', '64': 'PicardASMetrics', '65': 'cshl_fasta_formatter', '66': 'deeptools_profiler', '67': 'fastq_filter', '68': 'peakcalling_macs', '69': 'gemini_de_novo', '70': 'gatk2_variant_recalibrator', '71': 'gatk2_variant_apply_recalibration', '72': 'tab2fasta', '73': 'htseq_count', '74': 'tophat', '75': 'Count1', '76': 'bedtools_genomecoveragebed_bedgraph', '77': 'blastxml_to_tabular', '78': 'bamFilter', '79': 'bcftools_view', '80': 'deeptools_heatmapper', '81': 'bedtools_mergebed', '82': 'gemini_load', '83': 'modencode_peakcalling_macs2', '84': 'bg_uniq', '85': 'ctb_filter', '86': 'bwa_wrapper', '87': 'Summary_Statistics1', '88': 'join1', '89': 'Convert characters1', '90': 'bed_to_bigBed', '91': 'fasta_compute_length', '92': 'gtf2bedgraph', '93': 'cshl_fastq_to_fasta', '94': 'bowtie2', '95': 'Paste1', '96': 'cshl_word_list_grep', '97': 'deeptools_bigwigCompare', '98': 'vcfallelicprimitives', '99': 'samtools_rmdup', '100': 'EMBOSS: shuffleseq87', '101': 'gemini_comp_hets', '102': 'IDMapper', '103': 'cshl_multijoin', '104': 'methtools_dmr', '105': 'addValue', '106': 'Remove beginning1', '107': 'ctb_change_title', '108': 'ProteinQuantifier', '109': 'EMBOSS: fuzzpro38', '110': 'bgchem_fragment_merger', '111': 'bamCoverage_deepTools', '112': 'gtf_filter_by_attribute_values_list', '113': 'createInterval', '114': 'proteomics_search_peptide_prophet_1', '115': 'macs2_callpeak', '116': 'heatmapper', '117': 'Extract_features1', '118': 'methtools_calling', '119': 'bamCompare_deepTools', '120': 'cshl_awk_replace_in_column', '121': 'IDPosteriorErrorProbability', '122': 'gatk2_reduce_reads', '123': 'cshl_awk_tool', '124': 'deeptools_bamCompare', '125': 'rsem_calculate_expression', '126': 'gatk2_variant_select', '127': 'methtools_tiling', '128': 'charts', '129': 'computeMatrix', '130': 'hgv_david', '131': 'bam2wig', '132': 'sample_seqs', '133': 'freebayes', '134': 'sam2interval', '135': 'FalseDiscoveryRate', '136': 'correctGCBias', '137': 'bed2gff1', '138': 'cshl_cut_tool', '139': 'varscan', '140': 'Remove_ending', '141': 'fasta2tab', '142': 'deeptools_bamCorrelate', '143': 'ctb_remIons', '144': 'naive_variant_caller', '145': 'CONVERTER_interval_to_bgzip_0', '146': 'gatk2_indel_realigner', '147': 'openms_id_file_converter', '148': 'bedtools_bamtobed', '149': 'picard_ReorderSam', '150': 'bedtools_intersectBed', '151': 'glimmer_knowlegde-based', '152': 'rmcontamination', '153': 'Show beginning1', '154': 'EMBOSS: newseq59', '155': 'deeptools_correctGCBias', '156': 'wc_gnu', '157': 'cshl_uniq_tool', '158': 'ctb_simsearch', '159': 'methtools_destrand', '160': 'gops_intersect_1', '161': 'htseq-count', '162': 'samtools_mpileup', '163': 'gops_subtract_1', '164': 'snpSift_annotate', '165': 'cshl_fastx_trimmer', '166': 'gemini_pathways', '167': 'translate_bed_sequences', '168': 'gatk2_variant_annotator', '169': 'Datamash', '170': 'deeptools_computeMatrix', '171': 'EMBOSS: water107', '172': 'silac_analyzer', '173': 'PeptideIndexer', '174': 'deeptools_computeGCBias', '175': 'ncbi_makeblastdb', '176': 'scaffold2fasta', '177': 'methtools_filter', '178': 'samtools_sort', '179': 'Extract genomic DNA 1', '180': 'rseqc_bam2wig', '181': 'seq_filter_by_id', '182': 'sam_merge2', '183': 'wig_to_bigWig', '184': 'find_in_reference', '185': 'Grep1', '186': 'CONVERTER_bedgraph_to_bigwig', '187': 'cat1', '188': 'dt_profiler', '189': 'EMBOSS: geecee41', '190': 'gatk2_base_recalibrator', '191': 'Add_a_column1', '192': 'FeatureFinderMultiplex', '193': 'CONVERTER_bed_gff_or_vcf_to_bigwig_0', '194': 'msconvert3_raw', '195': 'CONVERTER_gff_to_bed_0', '196': 'fastqc', '197': 'get_flanks1', '198': 'bwa_mem', '199': 'picard_ARRG', '200': 'gff2bed1', '201': 'vt_normalize', '202': 'bedtools_subtractbed', '203': 'blockbuster', '204': 'ncbi_tblastn_wrapper', '205': 'bismark_bowtie', '206': 'cshl_fastx_clipper', '207': 'deseq2_single', '208': 'IDFilter', '209': 'gemini_query', '210': 'fastq_groomer', '211': 'bedtools_multiintersectbed', '212': 'barchart_gnuplot', '213': 'snpSift_filter', '214': 'gatk2_haplotype_caller', '215': 'cshl_sed_tool', '216': 'gemini_burden', '217': 'EMBOSS: fuzztran39', '218': 'CONVERTER_bed_to_bgzip_0', '219': 'infernal_cmsearch', '220': 'IDMerger', '221': 'FileMerger', '222': 'snpSift_geneSets', '223': 'openms_protein_quantifier', '224': 'Filter1', '225': 'snpEff', '226': 'histogram_rpy', '227': 'bedtools_intersectbed_bam', '228': 'rsem_prepare_reference', '229': 'smooth_running_window', '230': 'bedtools_coveragebed_counts', '231': 'openms_id_mapper', '232': 'filter_bed_on_splice_junctions', '233': 'trim_galore', '234': 'allele_counts_1', '235': 'XY_Plot_1', '236': 'CONVERTER_interval_to_bed_0', '237': 'cshl_easyjoin', '238': 'Show tail1', '239': 'methtools_plot', '240': 'cshl_find_and_replace', '241': 'trimmer', '242': 'deeptools_bamCoverage', '243': 'out_tool', '244': 'Cut1', '245': 'vcffilter', '246': 'FidoAdapter'}\n"
     ]
    }
   ],
   "source": [
    "#base_path = \"data/rnn_custom_loss/complete_training/\"\n",
    "base_path = \"data/models/\"\n",
    "\n",
    "#model_path = base_path + \"trained_model_19_09_1.h5\"\n",
    "model_path = base_path + \"tool_recommendation_model.hdf5\"\n",
    "\n",
    "trained_model = h5py.File(model_path, 'r')\n",
    "model_config = json.loads(trained_model.get('model_config').value)\n",
    "class_weights = json.loads(trained_model.get('class_weights').value)\n",
    "    \n",
    "loaded_model = model_from_json(model_config)\n",
    "dictionary = json.loads(trained_model.get('data_dictionary').value)\n",
    "compatibile_tools = json.loads(trained_model.get('compatible_tools').value)\n",
    "best_params = json.loads(trained_model.get('best_parameters').value)\n",
    "\n",
    "model, dictionary, reverse_dictionary, compatibile_tools = create_model(model_path)\n",
    "\n",
    "print(reverse_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted tools: \n",
      "\n",
      "{'tab2fasta': 100, 'cor2': 100, 'Show tail1': 100, 'cshl_word_list_grep': 100, 'CONVERTER_interval_to_bgzip_0': 100, 'CONVERTER_bedgraph_to_bigwig': 100, 'Grep1': 100, 'sort1': 100, 'wig_to_bigWig': 100, 'CONVERTER_interval_to_bed_0': 100, 'Add_a_column1': 99, 'join1': 99, 'wc_gnu': 99, 'Filter1': 99, 'XY_Plot_1': 99, 'cshl_uniq_tool': 99, 'cshl_sort_header': 99, 'Paste1': 99, 'addValue': 99, 'Convert characters1': 99, 'Summary_Statistics1': 99, 'gops_intersect_1': 99, 'Count1': 99, 'bedtools_intersectbed_bam': 99, 'methtools_filter': 99, 'cat1': 99, 'r_correlation_matrix': 99, 'cshl_find_and_replace': 99, 'bedtools_genomecoveragebed_bedgraph': 99, 'Remove beginning1': 99}\n",
      "\n",
      "Class weights: \n",
      "\n",
      "{}\n",
      "\n",
      "Usage weights: \n",
      "\n",
      "{}\n",
      "\n",
      "Mean usage wt: nan\n",
      "\n",
      "Inverted weights: \n",
      "\n",
      "{}\n",
      "\n",
      "Tool ids\n",
      "{'tab2fasta': 72, 'cor2': 22, 'Show tail1': 238, 'cshl_word_list_grep': 96, 'CONVERTER_interval_to_bgzip_0': 145, 'CONVERTER_bedgraph_to_bigwig': 186, 'Grep1': 185, 'sort1': 19, 'wig_to_bigWig': 183, 'CONVERTER_interval_to_bed_0': 236, 'Add_a_column1': 191, 'join1': 88, 'wc_gnu': 156, 'Filter1': 224, 'XY_Plot_1': 235, 'cshl_uniq_tool': 157, 'cshl_sort_header': 9, 'Paste1': 95, 'addValue': 105, 'Convert characters1': 89, 'Summary_Statistics1': 87, 'gops_intersect_1': 160, 'Count1': 75, 'bedtools_intersectbed_bam': 227, 'methtools_filter': 177, 'cat1': 187, 'r_correlation_matrix': 15, 'cshl_find_and_replace': 240, 'bedtools_genomecoveragebed_bedgraph': 76, 'Remove beginning1': 106}\n",
      "======================================\n"
     ]
    }
   ],
   "source": [
    "topk = 30\n",
    "tool_seq = \"244\"\n",
    "class_wt, usage_wt, inverse_wt, pred_tools = verify_model(model, tool_seq, \"\", dictionary, reverse_dictionary, compatibile_tools, class_weights, topk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.556972389179466"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights['294']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
